# 메모리 계층

<img width="500" src="https://github.com/user-attachments/assets/8426ea89-2256-4fe2-90e5-a4b7998dd052" />

- 레지스터, 캐시, 메모리, 저장장치로 구성
  - 레지스터: CPU 안에 있는 작은 메모리. 휘발성, 가장 빠른 속도, 가장 적은 기억 용량
  - 캐시: L1, L2 캐시를 지칭. 휘발성, 빠른 속도, 적은 기억 용량 (L3 캐시도 존재)
  - 주기억장치: RAM을 지칭. 휘발성, 속도 보통, 기억 용량 보통
  - 보조기억장치: HDD, SDD를 일컬으며 비휘발성, 속도 낮음, 많은 기억 용량
- 계층이 있는 이유는 경제성과 캐시 때문에 존재

## 캐시 (cache)

- 데이터를 미리 복사해 놓는 임시 저장소
- 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

=> 데이터 접근 시간이 오래 걸리는 경우를 해결, 무언가 다시 계산하는 시간 절약

- 캐시 계층: 계층과 계층 사이의 속도 차이를 해결하기 위해 중간에 두는 계층

### 지역성의 원리

캐시 계층을 두는 것 말고 캐시를 직접 설정해야 할 땐?
-> 자주 사용하는 데이터 기반으로 설정
-> 이에 근거가 되는 것이 지역성

- **시간 지역성**: 최근 사용한 데이터에 다시 접근하려는 특성
- **공간 지역성**: 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

## 캐시히트와 캐시미스

- 캐시히트: 캐시에서 원하는 데이터를 발견
- 캐시미스: 원하는 데이터가 캐시에 없어 주 메모리로 가서 데이터를 찾아오는 것
<img width="500" src="https://github.com/user-attachments/assets/0b9eb16b-9e2a-41b1-bcb2-b56414262442" />

- 캐시히트를 하게 되면 해당 데이터를 제어장치를 거쳐 가져온다
  - 위치도 가깝고, CPU 내부버스를 기반으로 작동하기 때문에 빠르다
- 캐시미스가 발생되면 메모리에서 가져온다
  - 시스템 버스를 기반으로 작동하기 때문에 느리다

### 캐시 매핑

- 캐시가 히트되기 위해 매핑하는 방법
- CPU의 레지스터와 주 메모리 (RAM) 간에 데이터를 주고받을 때를 기반으로 설명
- 레지스터는 주 메모리에 비해 매우 작기 때문에 작은 레지스터가 캐시 계층으로써 역할을 잘 해주려면 매핑을 어떻게 하느냐가 중요

<img width="800" src="https://github.com/user-attachments/assets/bc4cfe54-c907-4cf7-9878-7024ec2a3ef4" />

### 웹 브라우저의 캐시

- 사용자의 커스텀 정보나 인증 모듈 관련 사항을 웹 브라우저에 저장
- 추후 서버 요청 시 사용자의 아이덴티티를 나타내거나 중복 요청 방지를 위해 활용

**쿠키**

- 만료 기한이 있는 키-값 저장소
- 4KB까지 데이터 저장 가능
- 클라이언트, 서버 둘 다 만료기한 설정 가능, 보통 서버
- 쿠키를 설정할 땐 document.cookie로 쿠키를 볼 수 없게 httponly 옵션을 거는 것이 중요

**로컬 스토리지**

- 만료 기한이 없는 키-값 저장소
- 10MB까지 저장 가능
- 웹 브라우저를 닫아도 유지, 도메인 단위로 저장 및 생성
- 클라이언트에서만 수정 가능

**세션 스토리지**

- 만료기한이 없는 키-값 저장소
- 5MB까지 저장 가능
- 탭 단위로 생성, 탭 닫으면 해당 데이터 삭제
- 클라이언트에서만 수정 가능

### 데이터베이스의 캐싱 계층

- 데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 캐싱 계층으로 두어 성능 향상
<img width="500" src="https://github.com/user-attachments/assets/54a57840-4b04-4ce1-9e4f-00795da05567" />

<br />

# 메모리 관리

컴퓨터 내의 한정된 메모리를 극한으로 활용해야 하기 때문에 메모리 관리가 중요

## 가상 메모리 (virtual memory)

- 메모리 관리 기법 중 하나
- 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 메모리 자원이 더 크게 보이도록 만들어주는 기술
- 가상 메모리는 가상 주소와 실제 주소가 매핑되어있음
  - 가상 주소(logical address): 가상으로 주어진 주소
    - 메모리관리장치(MMU)에 의해 실제 주소로 변환
  - 실제 주소(physical address): 실제 메모리상에 있는 주소
- 프로세스 주소 정보가 들어있는 페이지 테이블로 관리
  - 속도 향상을 위해 TLB 사용
    > TLB: 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시. 페이지 테이블에 있는 리스트를 보관, CPU가 페이지 테이블까지 가지 않도록 하여 속도 향상

<img width="600" src="https://github.com/user-attachments/assets/401828a2-1646-4777-9e26-2ee4a9f58337" />

- 컴퓨터 메모리: 실제 메모리 자원
- MMU(Memory Management Unit): 가상 주소를 실제 주소로 변환
- 가상 메모리: 프로그램이 사용하는 메모리 공간, 실제 메모리 초과 가능
- 캐시: 주 메모리보다 빠른 임시 저장소, 자주 사용하는 데이터 저장
- 메인 메모리: 컴퓨터의 주 메모리, RAM 등
- 디스크: HDD나 SSD로, 데이터를 영구적으로 저장

### 스와핑

- 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것
- 페이지 폴트를 방지하기 위한 것

### 페이지 폴트

필요한 데이터를 메모리(RAM)에서 찾지 못했을 때 발생

**페이지 폴트로 인한 스와핑 과정**

1. CPU는 물리 메모리(RAM)를 확인하여 해당 페이지가 없으면 트랩이라는 신호를 발생시켜 운영체제에 알림
2. 운영체제는 CPU의 동작을 잠시 멈춤
3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인, 없으면 프로세스 중단 후 현재 메모리에 비어있는 프레임이 있는지 찾음. 물리 메모리에도 없다면 스와핑 필요.
4. 비어 있는 프레임에 하드디스크에서 해당 페이지를 로드, 페이지 테이블 최신화
5. CPU 재시작

> 페이지: 가상 메모리를 사용하는 최소 크기 단위
> 프레임: 실제 메모리를 사용하는 최소 크기 단위

<br />

## 스레싱 (thrashing)

메모리의 페이지 폴트율이 높은 것을 의미 -> 컴퓨터의 심각한 성능 저하를 초래

<img width="500" src="https://github.com/user-attachments/assets/5342229c-a5fc-4c96-8eb9-cb7d8fb194c4" />

- 메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 일어나서 발생
- 페이지 폴트가 일어나면 CPU 이용률이 낮아짐
- CPU 이용률이 낮아지면 운영체제는 CPU가 한가하다고 생각하고 가용성을 더 높이기 위해 더 많은 프로세스를 메모리에 올림
- 해결 방법
  - 메모리 늘리기
  - HDD를 사용하면 HDD를 SDD로 바꾸기
  - 운영체제에서 해결
    - 작업 세트(working set): 프로레스의 지역성을 통해 결정된 페이지 집합을 만들어 미리 메모리에 로드
    - PFF(Page Fault Frequency): 페이지 폴트 빈도를 조절하는 방법, 상한선과 하한선을 만듦

<br />

## 메모리 할당

메모리에 프로그램을 할당할 땐 시작 메모리 위치, 메모리 할당 크기를 기반으로 할당

### 연속 할당

메모리에 연속적으로 공간을 할당하는 것

<img width="500" src="https://github.com/user-attachments/assets/1a86afad-c0b4-4630-bd2b-25a6fa309357" />

- 위 그림처럼 A, B, C 프로세스를 순차적으로 공간에 할당
- 고정 분할 방식: 메모리를 미리 나누어 관리. 융통성 X, 내부 단편화 발생
- 가변 분할 방식: 매 시점 프로그램의 크기에 맞게 메모리를 분할하여 사용. 외부 단편화 발생.
  ![image](https://github.com/user-attachments/assets/fdd0f71b-4925-49d2-9906-747494a6eb73)

> **내부 단편화**: 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
> **외부 단편화**: 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상. 예를 들어 100MB를 55MB, 45MB로 나눴는데 프로그램 크기가 70MB라 들어가지 못할 때
> **홀**: 할당할 수 있는 비어 있는 메모리 공간

### 불연속 할당

메모리를 연속적으로 할당하지 않는 것으로 현대 운영체제가 쓰는 방법

**페이징 기법**

- 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당하는 것
- 홀의 크기가 균일하지 않은 문제가 없어짐
  - 페이지 크기가 동일하므로
- 주소 변환이 복잡
  - 프로그램이 사용하는 가상 주소를 물리 주소로 변환하기 위해 페이지 테이블을 참조해야 하므로

**세그멘테이션**

- 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식
- 세그먼트는 일반적으로 프로그램의 논리적 구성요소(코드, 데이터, 스택 등)
- 공유와 보안 측면에서 좋음
  - 여러 프로세스가 같은 세그먼트를 공유할 수 있어 메모리 사용 효율성 높음
  - 세그먼트 단위로 접근 제어 가능하여 보안 측면에서도 유리
- 홀 크기가 균일하지 않은 문제 발생
  - 세그먼트 크기가 다양하므로

**페이지드 세그멘테이션**

- 공유나 보안을 의미 단위의 세그먼트로 나눔
- 물리적 메모리는 페이지로 나눔

<br />

## 페이지 교체 알고리즘

메모리는 한정되어 있어 스와핑이 자주 발생.
스와핑이 많이 일어나지 않도록 설계하기 위해 페이지 교체 알고리즘을 사용

### 오프라인 알고리즘

- 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘
- 사용할 수 없음, 그치만 다른 알고리즘과의 성능 비교에 대한 기준을 제공

**FIFO**

- 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

**LRU** (Least Recently Used)

- 참조가 가장 오래된 페이지를 교체
<img width="300" src="https://github.com/user-attachments/assets/70c5429e-63fb-41f4-a49f-93c6548155f4" />

위 그림에서 5번째에 5번 페이지가 들어왔을 때 가장 오래된 1번 페이지와 스왑

**NUR** (Not Used Recently)

- LRU에서 발전, clock 알고리즘이라고도 함
- 0과 1을 가진 비트를 두어 1은 최근에 참조된 것, 0은 참조되지 않음을 의미.

<img width="400" src="https://github.com/user-attachments/assets/4a9b917f-6af9-47d3-a095-1cc850b1c8c0" />

시계방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고 해당 부분을 1로 바꿈

**LFU** (Least Frequently Used)

- 가장 참조 횟수가 적은 페이지 교체

---

# 면접 예상 질문

- 데이터 지역성은 어떻게 나뉘는가?
- 가상 메모리가 무엇이고 나온 이유
- 스와핑이란?
- 페이징 기법 또는 세그멘테이션을 사용하는 이유
- 페이징과 세그멘테이션의 차이
- 페이지 교체 알고리즘이 무엇이고 어떠한 것들이 있는지
